{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID-19 Research Papers LDA Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the LDA model to create topics, or clusters, present in the dataset using the abstracts of the papers. Each topic is corresponds to a set of word-probability pairs, and I chose to use the top 15 highest probability words of each topic to represent the given topic. Each paper is assigned a topic based on how many of the top 15 words of each topic are included in the abstract, and how often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jayfeng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/jayfeng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jayfeng/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords \n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('punkt')\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "nltk.download('wordnet')\n",
    "\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Reads in abstracts.csv and filters out rows with missing values.\"\"\"\n",
    "\n",
    "df = pd.read_csv(\"abstracts.csv\")\n",
    "df = df[df[\"abstract\"] != \"NaN\"]\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Set up stop words, stemmer, and lemmatizer.\"\"\"\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "snowBallStemmer = SnowballStemmer(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tokenize and clean the abstracts of every paper.\"\"\"\n",
    "\n",
    "def tokenize_clean(abstract):\n",
    "    #tokenizes abstract string\n",
    "    tokens = word_tokenize(abstract.lower())\n",
    "    \n",
    "    #lemmatizes tokens\n",
    "    counter = 0\n",
    "    while counter < len(tokens):\n",
    "        tokens[counter] = lemmatizer.lemmatize(tokens[counter])\n",
    "        counter += 1\n",
    "    \n",
    "    #filters, stems, and lowercases tokens\n",
    "    filtered_tokens = []\n",
    "    for i in tokens:\n",
    "        if i not in stop_words and len(i) > 3 and i != \"abstract\":\n",
    "            stemmed_word = snowBallStemmer.stem(i)\n",
    "            filtered_tokens.append(stemmed_word)\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "df[\"abstract tokens\"] = df.apply(lambda row: tokenize_clean(row.abstract), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Perform LDA topic modelling on a sample of the papers for speed purposes.\"\"\"\n",
    "\n",
    "partial_df = df#.sample(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create a list of lists of cleaned tokens of abstracts\"\"\"\n",
    "\n",
    "partial_texts = []\n",
    "for index, row in partial_df.iterrows():\n",
    "    partial_texts.append(row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Use gensim package to perform LDA topic modelling.\n",
    "Code from https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "used for reference.\n",
    "\"\"\"\n",
    "\n",
    "dictionary = corpora.Dictionary(partial_texts)\n",
    "dictionary.filter_extremes(no_below=3)\n",
    "\n",
    "corpus = [dictionary.doc2bow(text) for text in partial_texts]\n",
    "\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('cell', 0.025012113),\n",
       "   ('diseas', 0.012629243),\n",
       "   ('mous', 0.0115058),\n",
       "   ('lung', 0.010627538),\n",
       "   ('level', 0.0105229085),\n",
       "   ('express', 0.010188541),\n",
       "   ('respons', 0.009969395),\n",
       "   ('increas', 0.008813089),\n",
       "   ('immun', 0.008296855),\n",
       "   ('patient', 0.008231886),\n",
       "   ('studi', 0.00761007),\n",
       "   ('cytokin', 0.0069219493),\n",
       "   ('effect', 0.0066934),\n",
       "   ('activ', 0.0062856604),\n",
       "   ('signific', 0.006209401)]),\n",
       " (1,\n",
       "  [('use', 0.02553227),\n",
       "   ('detect', 0.015486624),\n",
       "   ('method', 0.015484636),\n",
       "   ('assay', 0.014352027),\n",
       "   ('develop', 0.01120945),\n",
       "   ('test', 0.01083256),\n",
       "   ('sensit', 0.010483696),\n",
       "   ('specif', 0.008285644),\n",
       "   ('result', 0.007763063),\n",
       "   ('studi', 0.006763329),\n",
       "   ('sampl', 0.006745366),\n",
       "   ('compound', 0.0064180945),\n",
       "   ('drug', 0.006367256),\n",
       "   ('effect', 0.006135174),\n",
       "   ('evalu', 0.005772998)]),\n",
       " (2,\n",
       "  [('health', 0.016095055),\n",
       "   ('covid-19', 0.014743369),\n",
       "   ('diseas', 0.014242308),\n",
       "   ('model', 0.00953684),\n",
       "   ('outbreak', 0.0085782325),\n",
       "   ('public', 0.007982136),\n",
       "   ('transmiss', 0.007166353),\n",
       "   ('control', 0.0069608986),\n",
       "   ('epidem', 0.006707769),\n",
       "   ('spread', 0.006673543),\n",
       "   ('emerg', 0.006599505),\n",
       "   ('data', 0.006464667),\n",
       "   ('popul', 0.0061146654),\n",
       "   ('infecti', 0.0060764933),\n",
       "   ('develop', 0.005507688)]),\n",
       " (3,\n",
       "  [('patient', 0.05007743),\n",
       "   ('respiratori', 0.02944156),\n",
       "   ('infect', 0.022321511),\n",
       "   ('virus', 0.019360073),\n",
       "   ('clinic', 0.015371755),\n",
       "   ('sever', 0.015270141),\n",
       "   ('hospit', 0.015104724),\n",
       "   ('covid-19', 0.014414585),\n",
       "   ('influenza', 0.013993063),\n",
       "   ('child', 0.013007579),\n",
       "   ('studi', 0.010167198),\n",
       "   ('case', 0.010076327),\n",
       "   ('detect', 0.009510728),\n",
       "   ('viral', 0.00916522),\n",
       "   ('pneumonia', 0.009002102)]),\n",
       " (4,\n",
       "  [('group', 0.025228752),\n",
       "   ('infect', 0.015288611),\n",
       "   ('sampl', 0.014494543),\n",
       "   ('studi', 0.013657948),\n",
       "   ('blood', 0.011790875),\n",
       "   ('calf', 0.00972588),\n",
       "   ('signific', 0.009540131),\n",
       "   ('diarrhea', 0.009500203),\n",
       "   ('anim', 0.009389972),\n",
       "   ('diseas', 0.008680263),\n",
       "   ('detect', 0.0076310122),\n",
       "   ('associ', 0.0074638086),\n",
       "   ('temperatur', 0.0065388335),\n",
       "   ('control', 0.006441913),\n",
       "   ('test', 0.0063822186)]),\n",
       " (5,\n",
       "  [('case', 0.036846355),\n",
       "   ('china', 0.027838847),\n",
       "   ('rate', 0.021549793),\n",
       "   ('wuhan', 0.020395927),\n",
       "   ('estim', 0.017113805),\n",
       "   ('number', 0.013769568),\n",
       "   ('result', 0.013564002),\n",
       "   ('use', 0.012159261),\n",
       "   ('model', 0.011111423),\n",
       "   ('report', 0.010786811),\n",
       "   ('provinc', 0.010773122),\n",
       "   ('method', 0.009973854),\n",
       "   ('time', 0.009886596),\n",
       "   ('data', 0.009441647),\n",
       "   ('conclus', 0.0086285705)]),\n",
       " (6,\n",
       "  [('virus', 0.050389726),\n",
       "   ('infect', 0.046315167),\n",
       "   ('cell', 0.02995177),\n",
       "   ('viral', 0.02743413),\n",
       "   ('host', 0.015739998),\n",
       "   ('replic', 0.014069702),\n",
       "   ('antivir', 0.011421271),\n",
       "   ('respons', 0.010719846),\n",
       "   ('human', 0.010295342),\n",
       "   ('immun', 0.00880785),\n",
       "   ('activ', 0.008088255),\n",
       "   ('express', 0.0070774597),\n",
       "   ('pathogen', 0.0067486493),\n",
       "   ('gene', 0.0065155732),\n",
       "   ('mechan', 0.0063566645)]),\n",
       " (7,\n",
       "  [('protein', 0.04806968),\n",
       "   ('activ', 0.01483482),\n",
       "   ('cell', 0.014015282),\n",
       "   ('structur', 0.013501383),\n",
       "   ('bind', 0.011682484),\n",
       "   ('function', 0.009097778),\n",
       "   ('membran', 0.008950824),\n",
       "   ('interact', 0.008784998),\n",
       "   ('express', 0.008416839),\n",
       "   ('domain', 0.008248983),\n",
       "   ('sars-cov', 0.007349306),\n",
       "   ('peptid', 0.006304611),\n",
       "   ('acid', 0.005990811),\n",
       "   ('show', 0.005874814),\n",
       "   ('studi', 0.0055033835)]),\n",
       " (8,\n",
       "  [('vaccin', 0.059646178),\n",
       "   ('antibodi', 0.034397326),\n",
       "   ('immun', 0.023970056),\n",
       "   ('virus', 0.018442173),\n",
       "   ('respons', 0.01424294),\n",
       "   ('antigen', 0.013758377),\n",
       "   ('pedv', 0.013148735),\n",
       "   ('protect', 0.012852038),\n",
       "   ('develop', 0.011432914),\n",
       "   ('neutral', 0.010083535),\n",
       "   ('strain', 0.009262977),\n",
       "   ('use', 0.009106534),\n",
       "   ('high', 0.008701911),\n",
       "   ('mous', 0.008672052),\n",
       "   ('recombin', 0.008477292)]),\n",
       " (9,\n",
       "  [('sequenc', 0.027051257),\n",
       "   ('virus', 0.026869839),\n",
       "   ('gene', 0.020333001),\n",
       "   ('genom', 0.018741027),\n",
       "   ('strain', 0.0146317575),\n",
       "   ('analysi', 0.012885357),\n",
       "   ('human', 0.011534871),\n",
       "   ('speci', 0.010243338),\n",
       "   ('identifi', 0.009279412),\n",
       "   ('genet', 0.008918503),\n",
       "   ('isol', 0.0085154995),\n",
       "   ('viral', 0.007813277),\n",
       "   ('differ', 0.007507083),\n",
       "   ('coronavirus', 0.00674352),\n",
       "   ('region', 0.0066429935)])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_results = ldamodel.show_topics(num_topics=10, num_words=15, formatted=False)\n",
    "lda_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cell',\n",
       "  'diseas',\n",
       "  'mous',\n",
       "  'lung',\n",
       "  'level',\n",
       "  'express',\n",
       "  'respons',\n",
       "  'increas',\n",
       "  'immun',\n",
       "  'patient',\n",
       "  'studi',\n",
       "  'cytokin',\n",
       "  'effect',\n",
       "  'activ',\n",
       "  'signific'],\n",
       " ['use',\n",
       "  'detect',\n",
       "  'method',\n",
       "  'assay',\n",
       "  'develop',\n",
       "  'test',\n",
       "  'sensit',\n",
       "  'specif',\n",
       "  'result',\n",
       "  'studi',\n",
       "  'sampl',\n",
       "  'compound',\n",
       "  'drug',\n",
       "  'effect',\n",
       "  'evalu'],\n",
       " ['health',\n",
       "  'covid-19',\n",
       "  'diseas',\n",
       "  'model',\n",
       "  'outbreak',\n",
       "  'public',\n",
       "  'transmiss',\n",
       "  'control',\n",
       "  'epidem',\n",
       "  'spread',\n",
       "  'emerg',\n",
       "  'data',\n",
       "  'popul',\n",
       "  'infecti',\n",
       "  'develop'],\n",
       " ['patient',\n",
       "  'respiratori',\n",
       "  'infect',\n",
       "  'virus',\n",
       "  'clinic',\n",
       "  'sever',\n",
       "  'hospit',\n",
       "  'covid-19',\n",
       "  'influenza',\n",
       "  'child',\n",
       "  'studi',\n",
       "  'case',\n",
       "  'detect',\n",
       "  'viral',\n",
       "  'pneumonia'],\n",
       " ['group',\n",
       "  'infect',\n",
       "  'sampl',\n",
       "  'studi',\n",
       "  'blood',\n",
       "  'calf',\n",
       "  'signific',\n",
       "  'diarrhea',\n",
       "  'anim',\n",
       "  'diseas',\n",
       "  'detect',\n",
       "  'associ',\n",
       "  'temperatur',\n",
       "  'control',\n",
       "  'test'],\n",
       " ['case',\n",
       "  'china',\n",
       "  'rate',\n",
       "  'wuhan',\n",
       "  'estim',\n",
       "  'number',\n",
       "  'result',\n",
       "  'use',\n",
       "  'model',\n",
       "  'report',\n",
       "  'provinc',\n",
       "  'method',\n",
       "  'time',\n",
       "  'data',\n",
       "  'conclus'],\n",
       " ['virus',\n",
       "  'infect',\n",
       "  'cell',\n",
       "  'viral',\n",
       "  'host',\n",
       "  'replic',\n",
       "  'antivir',\n",
       "  'respons',\n",
       "  'human',\n",
       "  'immun',\n",
       "  'activ',\n",
       "  'express',\n",
       "  'pathogen',\n",
       "  'gene',\n",
       "  'mechan'],\n",
       " ['protein',\n",
       "  'activ',\n",
       "  'cell',\n",
       "  'structur',\n",
       "  'bind',\n",
       "  'function',\n",
       "  'membran',\n",
       "  'interact',\n",
       "  'express',\n",
       "  'domain',\n",
       "  'sars-cov',\n",
       "  'peptid',\n",
       "  'acid',\n",
       "  'show',\n",
       "  'studi'],\n",
       " ['vaccin',\n",
       "  'antibodi',\n",
       "  'immun',\n",
       "  'virus',\n",
       "  'respons',\n",
       "  'antigen',\n",
       "  'pedv',\n",
       "  'protect',\n",
       "  'develop',\n",
       "  'neutral',\n",
       "  'strain',\n",
       "  'use',\n",
       "  'high',\n",
       "  'mous',\n",
       "  'recombin'],\n",
       " ['sequenc',\n",
       "  'virus',\n",
       "  'gene',\n",
       "  'genom',\n",
       "  'strain',\n",
       "  'analysi',\n",
       "  'human',\n",
       "  'speci',\n",
       "  'identifi',\n",
       "  'genet',\n",
       "  'isol',\n",
       "  'viral',\n",
       "  'differ',\n",
       "  'coronavirus',\n",
       "  'region']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Create topic_words, a list of buckets of words that represent each topic.\"\"\"\n",
    "\n",
    "topic_words = []\n",
    "#i is each topic\n",
    "for i in lda_results:\n",
    "    topic_i_words = []\n",
    "    word_pairs = i[1]\n",
    "    #j is the list of word-probability pairs (we don't care about the probabilities here)\n",
    "    for j in word_pairs:\n",
    "        topic_i_words.append(j[0])\n",
    "    topic_words.append(topic_i_words)\n",
    "        \n",
    "topic_words   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sha</th>\n",
       "      <th>abstract</th>\n",
       "      <th>abstract tokens</th>\n",
       "      <th>assigned topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9748</td>\n",
       "      <td>12331</td>\n",
       "      <td>f27a5562dd776c3a927ef078b0038ac690d03d90</td>\n",
       "      <td>Abstract Emergency departments play a critical...</td>\n",
       "      <td>[emerg, depart, play, critic, role, public, he...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4693</td>\n",
       "      <td>6316</td>\n",
       "      <td>9862f8f952ee3c06f71abde040191057aae32175</td>\n",
       "      <td>Abstract This study assesses viremia, provirus...</td>\n",
       "      <td>[studi, viremia, provirus, blood, cytokin, pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13388</td>\n",
       "      <td>17085</td>\n",
       "      <td>613b280bd1f7e0a0dd50cbf2501da003caf95eb4</td>\n",
       "      <td>Abstract The cough reflex is an attack of powe...</td>\n",
       "      <td>[cough, reflex, attack, power, expiratori, eff...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27091</td>\n",
       "      <td>39777</td>\n",
       "      <td>9c32d461dc9d4737756a990cf13bae1a03e078a9</td>\n",
       "      <td>The respiratory tract surface is protected fro...</td>\n",
       "      <td>[respiratori, tract, surfac, protect, inhal, p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13384</td>\n",
       "      <td>17080</td>\n",
       "      <td>b67c1adb9815a8ac0b118d1bd2f563d0d0e7c2bb</td>\n",
       "      <td>Publisher Summary Kawasaki disease (KD) is an ...</td>\n",
       "      <td>[publish, summari, kawasaki, diseas, acut, feb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15093</td>\n",
       "      <td>28926</td>\n",
       "      <td>868afcaa176cdfdc50900313a5657583d5a74e9e</td>\n",
       "      <td>In Ohio, United States, in early 2014, a delta...</td>\n",
       "      <td>[ohio, unit, state, earli, 2014, deltacoronavi...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15066</td>\n",
       "      <td>28898</td>\n",
       "      <td>8ccaf50414e8f530aaa405630c4e477d377d09ce</td>\n",
       "      <td>The complete genome of hepatitis E virus (HEV)...</td>\n",
       "      <td>[complet, genom, hepat, virus, laboratori, fer...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15048</td>\n",
       "      <td>28879</td>\n",
       "      <td>3399d0fe01c7cb8bff0615a506b7beacc813a05e</td>\n",
       "      <td>Our understanding of human disease and potenti...</td>\n",
       "      <td>[understand, human, diseas, potenti, therapeut...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25659</td>\n",
       "      <td>40632</td>\n",
       "      <td>06989a9659f1b9b10abc5b92a90ecff38a778d55</td>\n",
       "      <td>An old world fruit bat Pteropus giganteus, hel...</td>\n",
       "      <td>[world, fruit, pteropus, giganteus, held, capt...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15046</td>\n",
       "      <td>28877</td>\n",
       "      <td>db59c00ca304cff50531d66511fcf971f97a53ec</td>\n",
       "      <td>The identification of pathogens of viral (Rota...</td>\n",
       "      <td>[identif, pathogen, viral, rotavirus, coronavi...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24045 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                       sha  \\\n",
       "9748        12331  f27a5562dd776c3a927ef078b0038ac690d03d90   \n",
       "4693         6316  9862f8f952ee3c06f71abde040191057aae32175   \n",
       "13388       17085  613b280bd1f7e0a0dd50cbf2501da003caf95eb4   \n",
       "27091       39777  9c32d461dc9d4737756a990cf13bae1a03e078a9   \n",
       "13384       17080  b67c1adb9815a8ac0b118d1bd2f563d0d0e7c2bb   \n",
       "...           ...                                       ...   \n",
       "15093       28926  868afcaa176cdfdc50900313a5657583d5a74e9e   \n",
       "15066       28898  8ccaf50414e8f530aaa405630c4e477d377d09ce   \n",
       "15048       28879  3399d0fe01c7cb8bff0615a506b7beacc813a05e   \n",
       "25659       40632  06989a9659f1b9b10abc5b92a90ecff38a778d55   \n",
       "15046       28877  db59c00ca304cff50531d66511fcf971f97a53ec   \n",
       "\n",
       "                                                abstract  \\\n",
       "9748   Abstract Emergency departments play a critical...   \n",
       "4693   Abstract This study assesses viremia, provirus...   \n",
       "13388  Abstract The cough reflex is an attack of powe...   \n",
       "27091  The respiratory tract surface is protected fro...   \n",
       "13384  Publisher Summary Kawasaki disease (KD) is an ...   \n",
       "...                                                  ...   \n",
       "15093  In Ohio, United States, in early 2014, a delta...   \n",
       "15066  The complete genome of hepatitis E virus (HEV)...   \n",
       "15048  Our understanding of human disease and potenti...   \n",
       "25659  An old world fruit bat Pteropus giganteus, hel...   \n",
       "15046  The identification of pathogens of viral (Rota...   \n",
       "\n",
       "                                         abstract tokens  assigned topic  \n",
       "9748   [emerg, depart, play, critic, role, public, he...               0  \n",
       "4693   [studi, viremia, provirus, blood, cytokin, pro...               0  \n",
       "13388  [cough, reflex, attack, power, expiratori, eff...               0  \n",
       "27091  [respiratori, tract, surfac, protect, inhal, p...               0  \n",
       "13384  [publish, summari, kawasaki, diseas, acut, feb...               0  \n",
       "...                                                  ...             ...  \n",
       "15093  [ohio, unit, state, earli, 2014, deltacoronavi...               9  \n",
       "15066  [complet, genom, hepat, virus, laboratori, fer...               9  \n",
       "15048  [understand, human, diseas, potenti, therapeut...               9  \n",
       "25659  [world, fruit, pteropus, giganteus, held, capt...               9  \n",
       "15046  [identif, pathogen, viral, rotavirus, coronavi...               9  \n",
       "\n",
       "[24045 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Assign a topic to each of the papers.\"\"\"\n",
    "\n",
    "assigned_topic = []\n",
    "for index, row in partial_df.iterrows():\n",
    "    tokens = row[\"abstract tokens\"]\n",
    "    counter_array = [0] * 15\n",
    "    for i in tokens:\n",
    "        for j in np.arange(10):\n",
    "            if i in topic_words[j]:\n",
    "                counter_array[j] += 1\n",
    "    max_topic = counter_array.index(max(counter_array))\n",
    "    assigned_topic.append(max_topic)\n",
    "                \n",
    "partial_df[\"assigned topic\"] = assigned_topic\n",
    "partial_df = partial_df.sort_values(\"assigned topic\")\n",
    "partial_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_df.to_csv(\"document_clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
